{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a46b9a",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "In this Jupyter notebook I will be looking at missing values, outliers and how I am going to handle these.\n",
    "<br>\n",
    "<br>\n",
    "First of I need to calculate how many missing items there are in each row, however the file is too big to load into memory in a single file. This is where dask comes in; dask is a library that handles splitting up files and loading them into memory one at a time and calculating the results. Using dask I can set a maximum size that is allowed to be loaded into memory at ones, 32MB should be fine and still reasonably fast.\n",
    "<br>\n",
    "Below you can see the results of columns with their missing values total and percentage.\n",
    "\n",
    "| Column                          | Missing Count | Missing Percent|\n",
    "|---------------------------------|---------------|----------------|\n",
    "| Service:RDT-ID                  | 0             | 0.000000       |\n",
    "| Service:Date                    | 0             | 0.000000       |\n",
    "| Service:Type                    | 0             | 0.000000       |\n",
    "| Service:Company                 | 0             | 0.000000       |\n",
    "| Service:Train number            | 0             | 0.000000       |\n",
    "| Service:Completely cancelled    | 0             | 0.000000       |\n",
    "| Service:Partly cancelled        | 0             | 0.000000       |\n",
    "| Service:Maximum delay           | 0             | 0.000000       |\n",
    "| Stop:RDT-ID                     | 0             | 0.000000       |\n",
    "| Stop:Station code               | 182,170       | 0.125885       |\n",
    "| Stop:Station name               | 0             | 0.000000       |\n",
    "| Stop:Arrival time               | 16,127,855    | 11.144837      |\n",
    "| Stop:Arrival delay              | 16,127,855    | 11.144837      |\n",
    "| Stop:Arrival cancelled          | 16,127,855    | 11.144837      |\n",
    "| Stop:Departure time             | 15,859,427    | 10.959345      |\n",
    "| Stop:Departure delay            | 15,859,427    | 10.959345      |\n",
    "| Stop:Departure cancelled        | 15,859,427    | 10.959345      |\n",
    "| Stop:Platform change            | 0             | 0.000000       |\n",
    "| Stop:Planned platform           | 16,970,704    | 11.727271      |\n",
    "| Stop:Actual platform            | 16,970,704    | 11.727271      |\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d73eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\bramm\\AppData\\Local\\Temp\\ipykernel_21224\\1267378841.py:5: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  df = pd.read_csv('NS_Data\\combined_trein_data.csv', nrows=1_000_000)\n",
      "C:\\Users\\bramm\\AppData\\Local\\Temp\\ipykernel_21224\\1267378841.py:6: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  df.to_csv('NS_Data\\combined_trein_data_sample.csv', index=False)\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('NS_Data\\combined_trein_data.csv', nrows=1_000_000)\n",
    "df.to_csv('NS_Data\\combined_trein_data_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f7081c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed | 124.02 ms"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:34: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:34: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\bramm\\AppData\\Local\\Temp\\ipykernel_21224\\80343318.py:34: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  summary = missing_value_summary(\"NS_Data\\combined_trein_data_sample.csv\", blocksize=\"64MB\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 3.53 ss\n",
      "[########################################] | 100% Completed | 1.68 ss\n",
      "                              missing_count  missing_percent\n",
      "Service:RDT-ID                            0           0.0000\n",
      "Service:Date                              0           0.0000\n",
      "Service:Type                              0           0.0000\n",
      "Service:Company                           0           0.0000\n",
      "Service:Train number                      0           0.0000\n",
      "Service:Completely cancelled              0           0.0000\n",
      "Service:Partly cancelled                  0           0.0000\n",
      "Service:Maximum delay                     0           0.0000\n",
      "Stop:RDT-ID                               0           0.0000\n",
      "Stop:Station code                      1330           0.1330\n",
      "Stop:Station name                         0           0.0000\n",
      "Stop:Arrival time                    112901          11.2901\n",
      "Stop:Arrival delay                   112901          11.2901\n",
      "Stop:Arrival cancelled               112901          11.2901\n",
      "Stop:Departure time                  104673          10.4673\n",
      "Stop:Departure delay                 104673          10.4673\n",
      "Stop:Departure cancelled             104673          10.4673\n",
      "Stop:Platform change                      0           0.0000\n",
      "Stop:Planned platform                  4794           0.4794\n",
      "Stop:Actual platform                   4794           0.4794\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import pandas as pd\n",
    "\n",
    "def missing_value_summary(csv_path, blocksize=\"64MB\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute missing value counts and percentages for a CSV file using Dask.\n",
    "\n",
    "    Parameters:\n",
    "        csv_path (str): Path to the CSV file.\n",
    "        blocksize (str or int): Block size for Dask to load the CSV in chunks. Default is \"32MB\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing missing value counts and percentages per column.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load CSV lazily with Dask\n",
    "    df = dd.read_csv(csv_path, blocksize=blocksize)\n",
    "\n",
    "    with ProgressBar():\n",
    "        missing_summary = df.isnull().sum().compute()\n",
    "        row_count = df.shape[0].compute()\n",
    "\n",
    "    missing_percent = (missing_summary / row_count) * 100\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"missing_count\": missing_summary,\n",
    "        \"missing_percent\": missing_percent\n",
    "    })\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    summary = missing_value_summary(\"NS_Data\\combined_trein_data_sample.csv\", blocksize=\"64MB\")\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2518409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "def replace_missing_with_none(csv_path, column_name, blocksize=\"64MB\", output_path=None):\n",
    "    \"\"\"\n",
    "    Replace missing values (NaN and empty strings) in a specified column with \"NOCODE\".\n",
    "\n",
    "    Parameters:\n",
    "        csv_path (str): Path to the CSV file.\n",
    "        column_name (str): Column to replace missing values in.\n",
    "        blocksize (str or int): Block size for Dask to load the CSV in chunks.\n",
    "        output_path (str, optional): Path to save the modified CSV. If None, returns the Dask DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        dask.dataframe.DataFrame or None: Modified DataFrame if output_path is None, otherwise saves to file.\n",
    "    \"\"\"\n",
    "    # Load CSV lazily\n",
    "    df = dd.read_csv(csv_path, blocksize=blocksize)\n",
    "\n",
    "    # Replace empty strings and NaN values with \"NOCODE\"\n",
    "    df[column_name] = df[column_name].replace(\"\", \"NOCODE\").fillna(\"NOCODE\")\n",
    "\n",
    "    if output_path:\n",
    "        with ProgressBar():\n",
    "            df.to_csv(output_path, single_file=True, index=False)\n",
    "        print(f\"Modified dataset saved to {output_path}\")\n",
    "        return None\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "\n",
    "def replace_missing_with_value(csv_path, columns, value, blocksize=\"64MB\", output_path=None):\n",
    "    \"\"\"\n",
    "    Replace missing values (NaN and empty strings) in specified columns with a given value.\n",
    "\n",
    "    Parameters:\n",
    "        csv_path (str): Path to the CSV file.\n",
    "        columns (str or list): Column name(s) to replace missing values in.\n",
    "        value: The value to insert for missing values.\n",
    "        blocksize (str or int): Block size for Dask to load the CSV in chunks.\n",
    "        output_path (str, optional): Path to save the modified CSV. If None, returns the Dask DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        dask.dataframe.DataFrame or None: Modified DataFrame if output_path is None, otherwise saves to file.\n",
    "    \"\"\"\n",
    "    # Ensure columns is a list\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "\n",
    "    # Load CSV lazily\n",
    "    df = dd.read_csv(csv_path, blocksize=blocksize)\n",
    "\n",
    "    # Replace missing values in each specified column\n",
    "    for col in columns:\n",
    "        df[col] = df[col].replace(\"\", value).fillna(value)\n",
    "\n",
    "    if output_path:\n",
    "        with ProgressBar():\n",
    "            df.to_csv(output_path, single_file=True, index=False)\n",
    "        print(f\"Modified dataset saved to {output_path}\")\n",
    "        return None\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991b9bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed | 102.82 ms"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\bramm\\AppData\\Local\\Temp\\ipykernel_21224\\488088290.py:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  \"NS_Data\\combined_trein_data_sample.csv\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 8.68 ss\n",
      "Modified dataset saved to NS_Data/combined_trein_data_modified.csv\n",
      "[########################################] | 100% Completed | 7.53 ss\n",
      "Modified dataset saved to NS_Data/combined_trein_data_modified.csv\n",
      "[########################################] | 100% Completed | 7.77 ss\n",
      "Modified dataset saved to NS_Data/combined_trein_data_modified.csv\n",
      "[########################################] | 100% Completed | 7.42 ss\n",
      "Modified dataset saved to NS_Data/combined_trein_data_modified.csv\n",
      "[########################################] | 100% Completed | 7.79 ss\n",
      "Modified dataset saved to NS_Data/combined_trein_data_modified.csv\n",
      "[########################################] | 100% Completed | 2.60 ss\n",
      "[########################################] | 100% Completed | 1.48 ss\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Service:RDT-ID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Service:Date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Service:Type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Service:Company</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Service:Train number</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Service:Completely cancelled</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Service:Partly cancelled</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Service:Maximum delay</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop:RDT-ID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop:Station code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop:Station name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop:Arrival time</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop:Arrival delay</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop:Arrival cancelled</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop:Departure time</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop:Departure delay</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop:Departure cancelled</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop:Platform change</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop:Planned platform</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop:Actual platform</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              missing_count  missing_percent\n",
       "Service:RDT-ID                            0              0.0\n",
       "Service:Date                              0              0.0\n",
       "Service:Type                              0              0.0\n",
       "Service:Company                           0              0.0\n",
       "Service:Train number                      0              0.0\n",
       "Service:Completely cancelled              0              0.0\n",
       "Service:Partly cancelled                  0              0.0\n",
       "Service:Maximum delay                     0              0.0\n",
       "Stop:RDT-ID                               0              0.0\n",
       "Stop:Station code                         0              0.0\n",
       "Stop:Station name                         0              0.0\n",
       "Stop:Arrival time                         0              0.0\n",
       "Stop:Arrival delay                        0              0.0\n",
       "Stop:Arrival cancelled                    0              0.0\n",
       "Stop:Departure time                       0              0.0\n",
       "Stop:Departure delay                      0              0.0\n",
       "Stop:Departure cancelled                  0              0.0\n",
       "Stop:Platform change                      0              0.0\n",
       "Stop:Planned platform                     0              0.0\n",
       "Stop:Actual platform                      0              0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "replace_missing_with_none(\n",
    "        \"NS_Data\\combined_trein_data_sample.csv\",\n",
    "        \"Stop:Station code\",\n",
    "        blocksize=\"32MB\",\n",
    "        output_path=\"NS_Data/combined_trein_data_modified.csv\"\n",
    ")\n",
    "replace_missing_with_value(\n",
    "        \"NS_Data/combined_trein_data_modified.csv\",\n",
    "        [\"Stop:Planned platform\", \"Stop:Actual platform\"],\n",
    "        1,\n",
    "        blocksize=\"32MB\",\n",
    "        output_path=\"NS_Data/combined_trein_data_modified.csv\"\n",
    ")\n",
    "replace_missing_with_value(\n",
    "    \"NS_Data/combined_trein_data_modified.csv\",\n",
    "    [\"Stop:Arrival time\", \"Stop:Departure time\"],\n",
    "    -1,\n",
    "    blocksize=\"32MB\",\n",
    "    output_path=\"NS_Data/combined_trein_data_modified.csv\"\n",
    ")\n",
    "replace_missing_with_value(\n",
    "    \"NS_Data/combined_trein_data_modified.csv\",\n",
    "    [\"Stop:Arrival delay\", \"Stop:Departure delay\"],\n",
    "    0,\n",
    "    blocksize=\"32MB\",\n",
    "    output_path=\"NS_Data/combined_trein_data_modified.csv\"\n",
    ")\n",
    "replace_missing_with_value(\n",
    "    \"NS_Data/combined_trein_data_modified.csv\",\n",
    "    [\"Stop:Arrival cancelled\", \"Stop:Departure cancelled\"],\n",
    "    False,\n",
    "    blocksize=\"32MB\",\n",
    "    output_path=\"NS_Data/combined_trein_data_modified.csv\"\n",
    ")\n",
    "missing_value_summary(\"NS_Data/combined_trein_data_modified.csv\", blocksize=\"64MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe068d1c",
   "metadata": {},
   "source": [
    "1. Define the Prediction Objective (Target Variable Engineering)\n",
    "\n",
    "Clarify what exactly the model will output:\n",
    "\n",
    "Binary classification: Delay vs. no delay (define threshold, for example ≥5 minutes)\n",
    "\n",
    "Regression: Predicted delay in minutes\n",
    "\n",
    "Multi-class: Delay severity categories\n",
    "\n",
    "Ensure the target variable is constructed consistently for all records.\n",
    "\n",
    "2. Feature Engineering\n",
    "\n",
    "Convert raw data into informative predictors. Relevant temporal and operational features include:\n",
    "\n",
    "Scheduled time features: hour-of-day, weekday/weekend, month, holiday indicator\n",
    "\n",
    "Route-related features: previous station delay, next station connectivity\n",
    "\n",
    "Train metadata: train type (intercity, sprinter), operator, distance traveled\n",
    "\n",
    "Historical patterns: rolling averages of delays for same station and departure hour\n",
    "\n",
    "Weather (if available): precipitation, temperature, wind severity\n",
    "\n",
    "Ensure features are aligned with prediction time. The model must not see information from future events.\n",
    "\n",
    "3. Train–Station Graph Construction (if applying spatio-temporal learning)\n",
    "\n",
    "If modeling network dependencies:\n",
    "\n",
    "Represent each station as a node\n",
    "\n",
    "Define edges by direct rail connections\n",
    "\n",
    "Compute spatial adjacency matrix\n",
    "\n",
    "Add dynamic features like delay propagation from neighboring nodes\n",
    "\n",
    "This enables Temporal Graph models if you choose to use them later.\n",
    "\n",
    "4. Create a Proper Supervised Learning Dataset\n",
    "\n",
    "Split data into:\n",
    "\n",
    "Training set: historical range\n",
    "\n",
    "Validation set: more recent chronology\n",
    "\n",
    "Test set: the most recent period\n",
    "\n",
    "Avoid random splits because of temporal leakage.\n",
    "\n",
    "5. Baseline Models for Benchmarking\n",
    "\n",
    "Before advanced deep learning, establish reference performance:\n",
    "\n",
    "Historical mean/median delays per station/time slot\n",
    "\n",
    "Logistic regression or gradient boosting for binary likelihood\n",
    "\n",
    "ARIMA or Prophet for station-level time series\n",
    "\n",
    "These provide valuable benchmarks that your advanced model must outperform.\n",
    "\n",
    "6. Model Selection and Implementation\n",
    "\n",
    "You can start simple:\n",
    "\n",
    "Gradient Boosting Trees (XGBoost, LightGBM, CatBoost)\n",
    "\n",
    "Recurrent models (LSTM) if focusing on temporal sequences\n",
    "\n",
    "Then move toward spatio-temporal models:\n",
    "\n",
    "T-GCN\n",
    "\n",
    "Graph WaveNet\n",
    "\n",
    "Temporal Graph Transformers\n",
    "\n",
    "These capture delay propagation across the rail network.\n",
    "\n",
    "7. Evaluation Strategy\n",
    "\n",
    "Choose appropriate metrics:\n",
    "\n",
    "Classification: AUC, F1, Brier score for probability calibration\n",
    "\n",
    "Regression: RMSE, MAE\n",
    "\n",
    "Evaluate performance during specific scenarios:\n",
    "\n",
    "Peak hours vs. off-peak\n",
    "\n",
    "Weather-affected days\n",
    "\n",
    "Major events and holidays\n",
    "\n",
    "8. Model Explainability and Interpretation\n",
    "\n",
    "Add tools to understand why predictions are made:\n",
    "\n",
    "SHAP values for feature contributions\n",
    "\n",
    "Visual delay propagation graphs\n",
    "\n",
    "Station-level risk scores\n",
    "\n",
    "This improves practical usability.\n",
    "\n",
    "9. Optional: Multi-Task Extension\n",
    "\n",
    "If you want to predict both busyness and delay:\n",
    "\n",
    "Unified model with multiple outputs\n",
    "\n",
    "Shared spatio-temporal encoder with separate prediction heads\n",
    "\n",
    "This often yields better generalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-ns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
